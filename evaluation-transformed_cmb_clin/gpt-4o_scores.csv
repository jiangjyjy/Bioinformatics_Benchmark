Model,Shot,Fluency,Relevance,Completeness,Proficiency
internlm2_5-20b-hf,0shot,4.756756756756757,4.013513513513513,3.5675675675675675,3.8513513513513513
gpt-4o,5shot,4.878378378378378,4.675675675675675,4.635135135135135,4.594594594594595
llama-3_1-70b-instruct-hf,5shot,4.716216216216216,4.27027027027027,4.027027027027027,4.013513513513513
qwen2.5-72b-instruct-hf,5shot,4.972972972972973,4.878378378378378,4.878378378378378,4.864864864864865
yi-1.5-34b-chat-hf,5shot,4.216216216216216,4.121621621621622,3.9864864864864864,3.945945945945946
internlm2_5-20b-hf,5shot,4.675675675675675,4.216216216216216,3.945945945945946,4.094594594594595
mixtral-large-2-instruct-turbomind,5shot,4.375,3.888888888888889,3.3055555555555554,3.8472222222222223
gpt-4o,0shot,4.905405405405405,4.716216216216216,4.635135135135135,4.72972972972973
llama-3_1-70b-instruct-hf,0shot,4.890410958904109,4.3561643835616435,4.205479452054795,4.328767123287672
mixtral-large-2-instruct-turbomind,0shot,4.972972972972973,4.72972972972973,4.6891891891891895,4.716216216216216
qwen2.5-72b-instruct-hf,0shot,4.986301369863014,4.917808219178082,4.904109589041096,4.904109589041096
yi-1.5-34b-chat-hf,0shot,4.9324324324324325,4.594594594594595,4.378378378378378,4.405405405405405
